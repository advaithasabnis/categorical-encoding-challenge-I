[![LinkedIn][linkedin-shield]](https://www.linkedin.com/in/advaithasabnis/)

<br />
<p align="center">
  <a href="https://github.com/advaithasabnis/insight">
    <img src="images/header.png" alt="Logo" height="80">
  </a>
  <h3 align="center">Cat In The Dat</h3></p>

  <p align="center">
    An entry for the Categorical Feature Encoding Challenge
    <br />
    by Advait Hasabnis
</p>

## About
14th place solution (out of more than 1,300 submissions): https://www.kaggle.com/c/cat-in-the-dat/leaderboard

A common task in machine learning pipelines is encoding categorical variables for a given algorithm in a format that allows as much useful signal as possible to be captured.

In this entry I explored various encoding techniques for binary features, low- and high- cardinality nominal features, ordinal features and cyclical features.

<!-- CONTACT -->
## Author
<p><b>Advait Hasabnis</b></p>

Project Link: [https://github.com/advaithasabnis/categorical-encoding-challenge-I](https://github.com/advaithasabnis/categorical-encoding-challenge-I)
<br>
Kaggle Link: [https://www.kaggle.com/c/cat-in-the-dat/leaderboard](https://www.kaggle.com/c/cat-in-the-dat/leaderboard)


<!-- MARKDOWN LINKS & IMAGES -->
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=flat&logo=linkedin&colorB=2867B2